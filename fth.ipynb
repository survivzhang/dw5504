{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc1f3c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import os\n",
    "import csv\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c938f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"project\"\n",
    "DB_USER = \"postgres\"  # 默认用户名\n",
    "DB_PASSWORD = \"postgres\"  # 默认密码\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5433\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7fb9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"csv_debug_mining_results\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "432ff2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接到数据库\n",
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT\n",
    "        )\n",
    "        print(\"成功连接到数据库\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"连接数据库时出错: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "89338f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_db(conn):\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        p.road_user,\n",
    "        p.gender,\n",
    "        p.age_group,\n",
    "        t.day_of_week,\n",
    "        t.time_of_day,\n",
    "        v.bus_involvement,\n",
    "        v.heavy_rigid_truck_involvement,\n",
    "        v.articulated_truck_involvement,\n",
    "        r.national_road_type,\n",
    "        a.crash_type,\n",
    "        sp.christmas_period,\n",
    "        sp.easter_period,\n",
    "        l.state,\n",
    "        l.national_remoteness_areas,\n",
    "        s.speed_limit,\n",
    "        f.number_fatalities,\n",
    "        d.dwelling_records\n",
    "    FROM \n",
    "        accident_facts af\n",
    "    JOIN \n",
    "        personnel_dimension p ON af.personnelid = p.personnelid\n",
    "    JOIN \n",
    "        time_dimension t ON af.timeid = t.timeid\n",
    "    JOIN \n",
    "        vehicle_type_dimension v ON af.vehicleid = v.vehicleid\n",
    "    JOIN \n",
    "        road_type_dimension r ON af.roadid = r.roadid\n",
    "    JOIN \n",
    "        accident_info_dimension a ON af.crashtypeid = a.crashtypeid\n",
    "    JOIN \n",
    "        special_period_dimension sp ON af.specialperiodid = sp.specialperiodid\n",
    "    JOIN \n",
    "        location_dimension l ON af.locationid = l.locationid\n",
    "    JOIN \n",
    "        speed_limit_dimension s ON af.speedlimitid = s.speedlimitid\n",
    "    JOIN \n",
    "        fatality_dimension f ON af.fatalityid = f.fatalityid\n",
    "    JOIN\n",
    "        dwelling_dimension d ON af.dwellingid = d.dwellingid\n",
    "    WHERE \n",
    "        p.road_user NOT IN ('Unknown', 'Undetermined', 'Other/-9');\n",
    "    \"\"\"\n",
    "    return pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "46037617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # 转换速度限制为分类\n",
    "    df['speed_limit'] = pd.to_numeric(df['speed_limit'], errors='coerce')\n",
    "    df['speed_limit_category'] = df['speed_limit'].apply(\n",
    "        lambda x: 'Undetermined' if pd.isna(x) or x <= 0\n",
    "        else 'Low (≤50)' if x <= 50\n",
    "        else 'Medium (51-80)' if x <= 80\n",
    "        else 'High (>80)'\n",
    "    )\n",
    "    df = df.drop('speed_limit', axis=1)\n",
    "    \n",
    "    # 转换死亡人数为分类\n",
    "    df['number_fatalities'] = pd.to_numeric(df['number_fatalities'], errors='coerce')\n",
    "    df['fatalities_category'] = df['number_fatalities'].apply(\n",
    "        lambda x: 'Unknown' if pd.isna(x) or x < 0\n",
    "        else 'Normal' if x == 1\n",
    "        else 'Mid' if 2 <= x <= 3\n",
    "        else 'High'\n",
    "    )\n",
    "    df = df.drop('number_fatalities', axis=1)\n",
    "\n",
    "    # 转换dwelling records为分类\n",
    "    df['dwelling_records'] = pd.to_numeric(df['dwelling_records'], errors='coerce')\n",
    "    df['dwelling_category'] = df['dwelling_records'].apply(\n",
    "        lambda x: 'Unknown' if pd.isna(x) or x < 0\n",
    "        else 'Low' if x <= 10000\n",
    "        else 'Mid' if 10000 < x <= 50000\n",
    "        else 'High'\n",
    "    )\n",
    "    df = df.drop('dwelling_records', axis=1)\n",
    "    \n",
    "    # 确保所有列都是字符串类型\n",
    "    for col in df.columns:\n",
    "        if col != 'road_user':\n",
    "            df[col] = df[col].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ca69e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_1to1_rules(df, target_column='road_user', min_support=0.1, min_confidence=0.6):\n",
    "    rules_list = []\n",
    "    \n",
    "    # 获取目标列的唯一值\n",
    "    target_values = df[target_column].unique()\n",
    "    \n",
    "    for target in target_values:\n",
    "        for feature in df.columns:\n",
    "            if feature == target_column:\n",
    "                continue\n",
    "                \n",
    "            # 获取特征的唯一值\n",
    "            feature_values = df[feature].unique()\n",
    "            \n",
    "            for value in feature_values:\n",
    "                # 创建临时DataFrame进行分析\n",
    "                temp_df = pd.DataFrame()\n",
    "                temp_df[f\"{feature}_{value}\"] = (df[feature] == value).astype(int)\n",
    "                temp_df[f\"{target_column}_{target}\"] = (df[target_column] == target).astype(int)\n",
    "                \n",
    "                try:\n",
    "                    # 应用Apriori算法\n",
    "                    frequent_itemsets = apriori(temp_df, \n",
    "                                             min_support=min_support, \n",
    "                                             use_colnames=True)\n",
    "                    \n",
    "                    if frequent_itemsets.empty:\n",
    "                        continue\n",
    "                        \n",
    "                    # 生成规则\n",
    "                    rules = association_rules(frequent_itemsets, \n",
    "                                          metric=\"confidence\",\n",
    "                                          min_threshold=min_confidence)\n",
    "                    \n",
    "                    if rules.empty:\n",
    "                        continue\n",
    "                        \n",
    "                    # 筛选1->1规则\n",
    "                    for _, rule in rules.iterrows():\n",
    "                        ant = list(rule['antecedents'])[0]\n",
    "                        con = list(rule['consequents'])[0]\n",
    "                        \n",
    "                        if f\"{target_column}_{target}\" in [ant, con]:\n",
    "                            rules_list.append({\n",
    "                                'feature': feature,\n",
    "                                'feature_value': value,\n",
    "                                'target': target,\n",
    "                                'support': rule['support'],\n",
    "                                'confidence': rule['confidence'],\n",
    "                                'lift': rule['lift']\n",
    "                            })\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(rules_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "69b4bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rules_to_csv(rules_df):\n",
    "    if not rules_df.empty:\n",
    "        # 应用筛选条件\n",
    "        filtered_rules = rules_df[\n",
    "            (rules_df['support'] >= 0.05) &      # 最小支持度 0.2\n",
    "            (rules_df['confidence'] >= 0.6) &    # 最小置信度 0.6\n",
    "            (rules_df['lift'] > 1.0)            # 最小提升度 1.0\n",
    "        ]\n",
    "        \n",
    "        # 按lift降序排序\n",
    "        filtered_rules = filtered_rules.sort_values('lift', ascending=False)\n",
    "        \n",
    "        # 保存到CSV\n",
    "        output_file = os.path.join(output_dir, \"one_to_one_rules.csv\")\n",
    "        filtered_rules.to_csv(output_file, index=False)\n",
    "        \n",
    "        # 打印统计信息\n",
    "        print(f\"\\n规则筛选统计:\")\n",
    "        print(f\"筛选前规则数量: {len(rules_df)}\")\n",
    "        print(f\"筛选后规则数量: {len(filtered_rules)}\")\n",
    "        print(f\"规则已保存到: {output_file}\")\n",
    "        \n",
    "        # 打印一些基本统计\n",
    "        if not filtered_rules.empty:\n",
    "            print(\"\\n筛选后规则统计:\")\n",
    "            print(f\"平均支持度: {filtered_rules['support'].mean():.4f}\")\n",
    "            print(f\"平均置信度: {filtered_rules['confidence'].mean():.4f}\")\n",
    "            print(f\"平均提升度: {filtered_rules['lift'].mean():.4f}\")\n",
    "    else:\n",
    "        print(\"未找到符合条件的规则\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3666e26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功连接到数据库\n",
      "\n",
      "规则筛选统计:\n",
      "筛选前规则数量: 309\n",
      "筛选后规则数量: 30\n",
      "规则已保存到: csv_debug_mining_results/one_to_one_rules.csv\n",
      "\n",
      "筛选后规则统计:\n",
      "平均支持度: 0.1977\n",
      "平均置信度: 0.8505\n",
      "平均提升度: 1.1101\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    conn = connect_to_db()\n",
    "    if conn is None:\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        # 提取和预处理数据\n",
    "        df = extract_data_from_db(conn)\n",
    "        df = preprocess_data(df)\n",
    "        \n",
    "        # 挖掘规则\n",
    "        rules_df = mine_1to1_rules(\n",
    "            df,\n",
    "            min_support=0.005,\n",
    "            min_confidence=0.1\n",
    "        )\n",
    "        \n",
    "        # 保存规则\n",
    "        save_rules_to_csv(rules_df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"错误: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61eab56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
